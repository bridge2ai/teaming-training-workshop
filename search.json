[
  {
    "objectID": "facilitator-guide.html",
    "href": "facilitator-guide.html",
    "title": "Facilitator Guide",
    "section": "",
    "text": "In-Person:\n\nTables for 4-6 people (collaborative seating)\nWall space for posting flipchart sheets\nSupplies: markers, sticky notes, timer, flipchart paper\nName tags with first names only\n\nVirtual:\n\nPre-configured breakout rooms (4-5 people each)\nShared collaboration tool (Miro, Jamboard, or Padlet)\nPolls/surveys ready in platform\nChat moderation plan\n\n\n\n\n\nYou’re a guide, not a guru: Your science expertise gives you credibility, but participants’ experiences drive learning\nEmbrace productive discomfort: Some activities may feel unfamiliar - that’s intentional\nModel vulnerability: Share your own collaboration challenges when appropriate\n\n\n\n\n\n\n\n\n\n\nSay: “Raise your hand if you’ve ever been part of a research collaboration that felt effortless and productive.” [Pause for hands] “Keep your hand up if you’ve been part of one that was frustrating or unproductive.” [Usually more hands go up]\nTransition: “Today we’re going to unpack why some collaborations soar while others struggle, using evidence from the science of team science itself.”\n\n\n\nData to Share:\n\n2007 study of 19.9 million papers showed teams produce higher-impact research\nNobel Prize data: 42% of physics prizes since 2000 went to collaborations\nNIH success rates higher for multi-PI grants in many programs\n\nDiscussion Prompt: “What drives this trend toward collaboration in your field?”\nListen for: Complexity of problems, resource needs, interdisciplinary requirements, technology demands\nBridge: “But collaboration isn’t automatically better - it has to be done well.”\n\n\n\nCommon Failure Modes (present as bullets on slide):\n\nCoordination loss: Too much time spent organizing, not enough creating\nSocial loafing: Some members contribute less in group settings\nGroupthink: Pressure for consensus stifles critical thinking\nProcess conflict: Disagreements about how to work together\nGoal misalignment: Different objectives or success metrics\n\nFacilitator Note: Don’t dwell on failures - this sets up the solution-focused content ahead.\n\n\n\nThe IMPACT Framework:\n\nInterdependence: Members need each other to succeed\nMotivation: Shared purpose and individual engagement\nProcesses: Clear workflows and communication protocols\nAbilities: Complementary skills and expertise\nCulture: Trust, psychological safety, inclusion norms\nTools: Infrastructure for collaboration and data sharing\n\nFacilitator Tip: This framework threads through the entire training - refer back to it throughout.\n\n\n\n\n\n\nInstructions to Give: “Think of a research collaboration you’ve been part of - current or recent. Rate it on these six dimensions using a 1-5 scale, where 1 is ‘major weakness’ and 5 is ‘major strength.’ Be honest - this is for your learning.”\nDimensions to Rate:\n\nClear shared goals: Everyone understood what we were trying to achieve\nComplementary expertise: Team had the right mix of skills and knowledge\nEffective communication: Information flowed well, meetings were productive\nEquitable participation: All voices were heard, contributions were valued\nConflict resolution: We handled disagreements constructively\nResource sharing: Data, materials, and tools were accessible to team members\n\nFacilitator Actions:\n\nWalk around, but don’t look over shoulders\nGive 1-minute and 30-second warnings\nModel reflection by jotting your own notes\n\n\n\n\nInstructions: “Form groups of 4-5. Each person shares: 1. One area where your team was strongest (highest score) 2. One area that was most challenging (lowest score) 3. Don’t name the team or people - focus on the dynamics”\nYour Role:\n\nVisit each group briefly, listen for patterns\nNote common strengths and challenges on your notepad\nPrepare to synthesize themes in debrief\n\nListen for These Patterns:\n\nStrengths: Often include shared excitement about the problem, clear expertise divisions, strong PI leadership\nChallenges: Frequently communication breakdowns, unclear roles, data sharing difficulties, conflict avoidance\n\n\n\n\nProcess:\n\n“What themes did you hear in your groups about team strengths?”\n“What about common challenges?”\nCapture responses on flipchart/screen\n“Great - we’re going to address many of these challenges directly in our time together”\n\nTransition: “Let’s start with one of the most commonly cited issues: communication.”\n\n\n\n\n\n\n\n\n\n\nSay: “In that last activity, how many groups mentioned communication as a challenge?” [Show of hands] “Communication issues aren’t just annoying - they’re expensive. MIT research shows that poor communication costs organizations an average of $62.4 million per year.”\n\n\n\nPresent Framework: “Effective team communication has four essential elements - the 4 C’s:”\nClarity | Cadence | Channels | Culture\n“Let’s unpack each one with some science behind it.”\n\n\n\nResearch Basis: Hackman’s research on team design shows that clarity of purpose and process predicts team success better than member characteristics.\nPractical Application:\n\nMeeting agendas with time allocations\nDecision logs (what was decided, by whom, when)\nAction items with owners and deadlines\nShared glossaries for technical terms across disciplines\n\nDiscussion Prompt: “What happens in your experience when roles or expectations aren’t clear?”\nListen for: Duplicated work, missed deadlines, conflict, frustration\n\n\n\nResearch Basis: Gersick’s punctuated equilibrium model shows teams need regular check-ins to maintain momentum and adjust course.\nPractical Framework:\n\nDaily/Weekly: Tactical coordination (brief, operational)\nBi-weekly/Monthly: Strategic review (longer, reflective)\nQuarterly: Relationship maintenance (team building, big picture)\nAs-needed: Crisis management (rapid response protocols)\n\nKey Point: “Consistency matters more than frequency. Better to have monthly meetings that always happen than weekly ones that get cancelled.”\n\n\n\nResearch Basis: Media richness theory - different types of information need different communication channels.\nChannel Selection Guide:\n\nFace-to-face/Video: Complex discussions, sensitive topics, brainstorming\nPhone: Quick decisions, relationship building\nEmail: Documentation, detailed information sharing, non-urgent items\nChat/Slack: Quick questions, coordination, social connection\nShared documents: Collaborative creation, version control\n\nCommon Mistake: “Using email for everything. Email is terrible for discussions but great for decisions.”\n\n\n\nResearch Basis: Google’s Project Aristotle found psychological safety was the #1 predictor of team performance.\nEdmondson’s Definition: “A shared belief that the team is safe for interpersonal risk-taking.”\nObservable Behaviors:\n\nPeople ask questions without fear of appearing ignorant\nMistakes are discussed openly as learning opportunities\nDisagreement is expressed respectfully and directly\nDifferent perspectives are actively sought\n\nKey Insight: “This doesn’t mean being ‘nice’ all the time - it means being direct and kind simultaneously.”\n\n\n\n\n\n\nForm Teams: “Count off 1-5, find your number group. You’re going to create a communication charter that a real research team could use.”\nMaterials: Provide charter template, example excerpts, channel decision tree\n\n\n\nInstructions to Teams: “Imagine you’re starting a 2-year collaborative research project. Create a communication charter addressing these areas:”\nCharter Elements: 1. Communication Values (3-4 core principles) 2. Meeting Rhythms (frequency, duration, purpose of different meeting types) 3. Channel Guidelines (what goes where, response time expectations) 4. Decision-Making Process (how choices get made, who has input vs. final say) 5. Conflict Resolution (steps for handling disagreements)\nYour Role as Facilitator:\n\nCirculate between teams\nAsk clarifying questions: “How would this work in practice?” “What if someone doesn’t follow this?”\nKeep energy up with time calls\nLook for innovative approaches to highlight\n\nCommon Sticking Points and Responses:\n\n“This is too rigid” → “Think of it as a default, not a rule. You can always deviate with agreement”\n“Our team is different” → “Absolutely - customize this to your context”\n“We don’t have time for all these meetings” → “What’s the cost of poor coordination?”\n\n\n\n\nProcess: 1. Teams pair up and exchange charters 2. Each team provides feedback using this structure: - One strength: What works well in this charter? - One question: What needs clarification? - One suggestion: How could this be improved or strengthened?\nFeedback Guidelines to Share:\n\nBe specific rather than general\nFocus on workability, not personal preferences\nAsk questions if something is unclear\n\nYour Role:\n\nMonitor feedback quality - intervene if it’s too vague or harsh\nHelp teams stay on time\nNote particularly creative solutions for later sharing\n\n\n\n\n“Take the feedback you received and make one concrete revision to your charter.”\nWhy This Matters: Teams that practice giving and receiving feedback in low-stakes situations do better when conflicts arise.\n\n\n\n\n\n\n\n\n\n\nSay: “Communication helps teams work day-to-day, but governance determines how teams make big decisions and handle authority. Let’s look at what research tells us about structures that actually work.”\n\n\n\nKey Distinction:\n\nManagement: Day-to-day operations, task coordination, resource allocation\nGovernance: Decision rights, accountability structures, conflict resolution, strategic direction\n\nWhy It Matters: “Many teams focus only on management and wonder why they struggle with bigger decisions.”\n\n\n\nCore Principle: Different people lead different aspects based on expertise and interest.\nResearch Support: Pearce & Conger’s studies show distributed leadership increases team performance in knowledge work.\nStructure Example:\n\nScientific Leadership: Domain expert guides research direction\nOperational Leadership: Project manager handles logistics, timelines\nExternal Leadership: Senior person manages stakeholder relationships\nInnovation Leadership: Creative thinker drives new approaches\n\nPros: Leverages expertise, develops multiple people, reduces single points of failure Cons: Can be confusing if roles aren’t clear, may slow some decisions\nWhen It Works Best: Diverse, highly skilled teams with complex projects\n\n\n\nCore Principle: Leadership rotates based on project phase or expertise needs.\nReal Example: “In the Human Genome Project, different institutions led different phases based on their comparative advantages.”\nStructure Example:\n\nPhase 1: Data collection led by field research expert\nPhase 2: Analysis led by computational specialist\nPhase 3: Dissemination led by policy expert\n\nPros: Matches expertise to needs, develops multiple leaders Cons: Requires smooth handoffs, can create discontinuity\n\n\n\nCore Principle: Clear hierarchy with democratic input mechanisms.\nResearch Support: Tannenbaum & Schmidt’s leadership continuum research shows this balances efficiency with engagement.\nStructure Example:\n\nPrincipal Investigator: Final decision authority, external accountability\nAdvisory Council: Representative input from all stakeholder groups\nWorking Groups: Delegated authority for specific domains\n\nDecision Process:\n\nWorking groups develop recommendations\nAdvisory council provides input and alternatives\nPI makes final decision with transparent rationale\n\nPros: Clear accountability, incorporates diverse input, efficient Cons: Can feel top-down if not implemented well\n\n\n\nCore Principle: Hub-and-spoke coordination across autonomous units.\nReal Example: “Think of how the Large Hadron Collider collaboration works - thousands of scientists across hundreds of institutions.”\nStructure:\n\nCentral Coordination Hub: Manages overall project, standards, resources\nAutonomous Nodes: Independent teams with specific responsibilities\nLiaison Roles: Boundary spanners who connect nodes\n\nPros: Scales to large collaborations, maintains autonomy Cons: Complex coordination, potential for fragmentation\nKey Success Factor: Strong coordination mechanisms and shared standards\n\n\n\n\n\n\nFour Scenarios - Assign One Per Team:\n\nMulti-institutional Clinical Trial\n\n5 medical centers, 200 patients, 3-year timeline\nRegulatory compliance requirements, patient safety critical\n$2M budget, industry sponsor\n\nInterdisciplinary Data Analysis Consortium\n\nComputer scientists, social scientists, domain experts\nLarge shared dataset, multiple research questions\nDifferent publication norms across disciplines\n\nInternational Field Research Collaboration\n\nTeams from 4 countries, remote field sites\nEquipment sharing, varying resource levels\nDifferent institutional policies and cultures\n\nIndustry-Academic Partnership\n\nUniversity researchers + company R&D team\nProprietary data concerns, different timelines\nAcademic freedom vs. commercial interests\n\n\n\n\n\nInstructions to Teams: “Design a governance structure for your scenario. Address these key elements:”\nGovernance Elements to Address:\n\nLeadership Structure: Who has authority for what decisions?\nDecision-Making Process: How are key choices made?\nConflict Resolution: What happens when people disagree?\nResource Allocation: How are shared resources managed?\nCredit and Recognition: How are contributions acknowledged?\n\nDeliverable: Create a visual representation (flowchart, org chart, process diagram) that shows your governance model.\nYour Facilitation Approach:\n\nVisit each team twice during the 15 minutes\nFirst visit (5-7 min): Check understanding, clarify scenario details\nSecond visit (10-12 min): Push thinking with questions:\n\n“What happens if this person leaves the project?”\n“How do you handle a major disagreement using this structure?”\n“Where might this break down under pressure?”\n\n\nCommon Challenges and Responses:\n\nTeams default to simple hierarchy → “What are the downsides of that approach for this scenario?”\nTeams create overly complex structures → “How would new team members understand this?”\nTeams ignore the human dynamics → “What about trust, communication, relationships?”\n\n\n\n\nProcess:\n\nTeams post their governance designs around the room\nEveryone walks around and reviews all designs\nEach person gets 2 dot stickers to vote for:\n\nMost innovative approach\nMost practical for real implementation\n\n\nDebrief Questions:\n\n“What patterns do you see across the designs?”\n“What creative solutions surprised you?”\n“What would make these governance models actually work in practice?”\n\n\n\n\n\n\n\n\n\n\n\nAsk: “How many of you have been part of a collaboration where data sharing was seamless and easy?” [Few hands usually go up]\nSay: “Data sharing is often the biggest practical barrier to effective collaboration. Let’s look at frameworks that make it work.”\n\n\n\nPresent Framework: “The FAIR principles were designed for open science, but we need to extend them for collaborative team science.”\nFAIR Principles:\n\nFindable: Team members can locate relevant data and resources\nAccessible: Appropriate permissions and access protocols exist\nInteroperable: Data works across different systems and analyses\nReusable: Clear documentation enables future use\n\nThe ‘+’ Addition:\n\nSecure: Privacy, confidentiality, and compliance protections\n\n\n\n\nCommon Problem: “The data exists somewhere, but no one can find it when they need it.”\nSolutions:\n\nCentral registry of all project datasets with descriptions\nConsistent naming conventions for files and versions\nMetadata templates that everyone uses\nSearch functionality within shared repositories\n\nQuick Example: “Instead of ‘Analysis_final_v3_JMS.xlsx’, use ‘2024-03-15_participant-survey_cleaned_smith.xlsx’”\n\n\n\nKey Principle: “Default to open within the team, closed to the outside, with explicit exceptions.”\nAccess Levels:\n\nFull Access: Core team members, can read/write/modify\nAnalysis Access: Can download and analyze, cannot modify originals\n\nMetadata Access: Can see what exists, request specific datasets\nNo Access: Sensitive data with special restrictions\n\nImplementation Tools:\n\nCloud platforms with granular permissions (Google Drive, Box, institutional systems)\nVersion control systems (Git for code, specialized tools for data)\nAccess logging for sensitive data compliance\n\n\n\n\nCommon Failure: “Everyone saves data in their preferred format, nothing works together.”\nBest Practices:\n\nAgreed-upon file formats for different data types\nStandard variable naming across datasets\nCommon coding schemes for categorical variables\nDocumentation templates that everyone uses\n\n\n\n\nThe Documentation Imperative: “If you can’t understand the data 6 months from now, no one else will either.”\nEssential Documentation:\n\nData collection protocols and any changes over time\nVariable definitions and coding schemes\nQuality control procedures and known limitations\nAnalysis scripts with comments explaining logic\n\n\n\n\n\n\n\nScenario: Multi-site study examining social media use and mental health outcomes among adolescents. Site A (major university) has collected data from 500 participants. Site B (smaller college) wants to access this data for secondary analysis.\nRoles (5 people per group):\n\nSite A Principal Investigator: Collected the data, protective of participants\nSite B Researcher: Wants access for legitimate secondary research\nSite A Compliance Officer: Responsible for legal/ethical compliance\nSite B IRB Representative: Must ensure ethical standards\nData Manager: Technical expert on security and systems\n\nKey Constraints:\n\nData includes sensitive mental health information\nParticipants consented to “research by the study team and approved collaborators”\nSite A IRB approval required for data sharing\nSite B has different data security infrastructure\n\n\n\n\nInstructions to Groups: “You have 15 minutes to negotiate a data sharing agreement. You must address these issues:”\nRequired Agreement Elements:\n\nWhat data can be shared? (raw data, processed data, aggregate data only?)\nAccess controls: How will Site B access and store the data?\nPermitted analyses: What research questions can Site B pursue?\nPublication rights: How are publications handled? Authorship?\nSecurity requirements: What technical safeguards are needed?\nCompliance verification: How is adherence to agreement monitored?\n\nYour Facilitation Strategy:\n\nLet tensions emerge naturally - don’t smooth over disagreements too quickly\nIntervene only if discussion becomes personal or completely stuck\nNote common sticking points for debrief discussion\nWatch for creative solutions that balance competing interests\n\nCommon Sticking Points You’ll Observe:\n\nSite A wants extensive oversight, Site B wants autonomy\nPublication timelines and approval processes\nTechnical security requirements vs. practical constraints\nWhat happens if Site B violates the agreement\n\n\n\n\nDebrief Questions:\n\n“What was hardest to negotiate? Why?”\n“What solutions did you find for balancing protection with access?”\n“How did the different perspectives (PI vs. compliance vs. IRB) create tension?”\n“What would make this process easier in real life?”\n\nKey Learning Points to Draw Out:\n\nStart data sharing conversations early in collaboration planning\nDifferent stakeholders have legitimate but competing concerns\nTechnical solutions can resolve some trust issues\nClear agreements prevent bigger conflicts later\nTemplates and institutional support make negotiations faster\n\nTransition: “Data sharing is often where issues of fairness and inclusion become most visible. Let’s talk about building teams where everyone can contribute effectively.”\n\n\n\n\n\n\n\n\n\n\nResearch Foundation: “Three key findings from team performance research:”\n\nDiverse teams outperform homogeneous teams on complex problems (Page 2007)\nBut diversity alone isn’t enough - inclusion practices determine whether diversity helps or hurts (Nishii 2013)\nSmall changes in process can have big impacts on who participates and how (Woolley 2010)\n\nKey Insight: “Diversity is about composition. Inclusion is about behavior.”\n\n\n\nSurface-Level Diversity:\n\nDemographics: gender, race, age, nationality\nDisciplinary backgrounds\nInstitutional affiliations\nCareer stages\n\nDeep-Level Diversity:\n\nThinking styles (analytical vs. intuitive)\nWork preferences (individual vs. collaborative)\nCommunication styles (direct vs. indirect)\nRisk tolerance (conservative vs. experimental)\n\nWhy This Matters: “Surface-level diversity is what we see first, but deep-level diversity often drives the performance benefits.”\n\n\n\nAllport’s Contact Theory: Under the right conditions, contact between different groups reduces bias and improves collaboration.\nThe Right Conditions for Research Teams:\n\nEqual status within the collaboration context\nCommon goals that require interdependence\nIntergroup contact in cooperative (not competitive) settings\nAuthority support for collaborative norms\n\nPractical Application: “This means actively creating opportunities for different team members to work together as equals on shared objectives.”\n\n\n\nStrategy 1: Structured Brainstorming\n\nProblem: Extroverted team members dominate idea generation\nSolution: Silent brainstorming → individual sharing → group building\n\nStrategy 2: Devil’s Advocate Protocols\n\nProblem: Pressure for false consensus\nSolution: Assign someone to argue alternative perspectives\n\nStrategy 3: Multiple Communication Channels\n\nProblem: Some people don’t speak up in meetings\nSolution: Combine verbal discussion, written input, and one-on-one check-ins\n\nStrategy 4: Bias Interruption\n\nProblem: Unconscious biases affect evaluation of ideas and contributions\nSolution: Structured evaluation criteria, diverse review panels\n\nStrategy 5: Cultural Bridge-Building\n\nProblem: Different professional cultures have different norms\nSolution: Explicit discussion of differences, negotiated team norms\n\n\n\n\n\n\n\nInstructions: “Think about a current or recent research collaboration. Rate how well the team does on each inclusion indicator using a 1-5 scale.”\nInclusion Indicators:\n\nDiverse representation in leadership and decision-making roles\nEquitable participation in meetings and discussions\nMultiple communication styles are accommodated and valued\nDifferent perspectives are actively sought on important decisions\nCultural differences are acknowledged and leveraged as strengths\nBias mitigation strategies are used in evaluation and selection processes\nConflict resolution addresses both task and relationship issues\nRecognition and credit are distributed fairly across contributions\n\nFacilitator Notes:\n\nWalk around but maintain privacy\nNotice if people seem stuck - offer to clarify any indicators\nThis should be reflective, not judgmental\n\n\n\n\nPartner Assignment: “Find someone you don’t know well or haven’t worked with closely.”\nConversation Structure: Round 1 (3 minutes each person): Share assessment results\n\nWhich areas scored highest? What makes those work well?\nWhich areas scored lowest? What barriers do you see?\nDon’t problem-solve yet - just understand each other’s situations\n\nRound 2 (4 minutes total): Collaborative action planning\n\nChoose 2-3 priority areas for improvement\nBrainstorm specific, actionable strategies\nConsider: What would you try first? What support would you need?\n\nFacilitation Approach: - Circulate to listen for innovative ideas - Help pairs stay focused on actionable steps - Note themes for whole-group debrief\nCommon Challenges and Responses:\n\n“Our team is already pretty inclusive” → “That’s great! What could you share with other teams?”\n“These problems are too big for me to solve” → “What’s one small experiment you could try?”\n“I’m not in a leadership position” → “What can you influence from your current role?”\n\n\n\n\n\n\n\n\n\n\n\nReality Check: “Research on training effectiveness shows that without deliberate implementation support, people use about 10% of what they learn in programs like this.”\nWhy Implementation Fails: - Return to urgent daily pressures - Lack of organizational support - Trying to change too much at once - No accountability mechanisms\n\n\n\nPilot Approach: “Pick one practice, try it with one team, for one month.”\nExamples of Good Starting Points:\n\nCommunication: Implement structured agendas for one regular meeting\nGovernance: Create decision logs for one ongoing project\nData sharing: Establish naming conventions for one shared folder\nInclusion: Try silent brainstorming in one team meeting\n\nWhy This Works: Small wins build confidence and demonstrate value before scaling up.\n\n\n\nSimple Metrics for Team Effectiveness:\n\nEfficiency: Meeting satisfaction scores, time to decision\nInnovation: Number of new ideas generated, creative solutions adopted\nRelationships: Trust levels, conflict resolution speed\nOutcomes: Progress toward goals, quality of deliverables\n\nThe Learning Mindset: “Expect that your first attempts won’t be perfect. The goal is to learn and improve, not to implement flawlessly.”\n\n\n\nScaling Principles:\n\nAdapt, don’t just adopt: What works for one team may need modification for another\nBuild champions: Find early adopters who can help spread practices\nCreate systems support: Templates, training, and infrastructure\nAddress resistance: Understand and respond to legitimate concerns\n\nCommon Scaling Mistakes:\n\nMandating practices without buy-in\nIgnoring context differences\nMoving too fast without solidifying early wins\n\n\n\n\n\n\n\nInstructions: “Complete this action plan for yourself. Be specific and realistic.”\nTemplate Elements: 1. One thing I’ll stop doing in my research collaborations - Example: Stop sending unclear emails that require multiple follow-ups\n\nOne thing I’ll start doing within the next 30 days\n\nExample: Create a communication charter for my current project team\n\nOne practice I’ll advocate for in my existing teams\n\nExample: Propose using structured brainstorming for our next planning meeting\n\nMy accountability partner from this session\n\nName and contact information of someone who will check in with you\n\nCheck-in date to assess progress\n\nSpecific date within 60 days to review how implementation is going\n\nOne resource I need to make this work\n\nExample: Template for data sharing agreements, support from my department chair\n\n\nFacilitator Role:\n\nCirculate to answer questions and provide encouragement\nHelp people make their commitments specific and measurable\nConnect people who might be good accountability partners\n\n\n\n\nProcess: “Would anyone like to share one commitment with the group? This can help with accountability.”\nWhy This Works: Public commitments have higher follow-through rates.\nFacilitation Tips:\n\nDon’t pressure anyone to share\nCelebrate creative or ambitious commitments\nNote themes across commitments\n\n\n\n\n\n\n\n\n\n\nSend thank you email with session materials\nShare contact information for accountability partnerships\nProvide resource links and templates\n\n\n\n\n\nBrief survey on implementation attempts\nVirtual “office hours” for questions\nShare success stories and challenges\n\n\n\n\n\nFollow-up survey on sustained practice changes\nAdvanced workshop for graduates\nCommunity of practice formation\n\n\n\n\n\n\n\n\nSymptoms: Quiet groups, minimal discussion, brief activity outputs Interventions:\n\nUse smaller groups (3-4 people)\nProvide more structure and specific prompts\nModel vulnerability by sharing your own experiences\nUse anonymous input methods (sticky notes, digital polls)\n\n\n\n\nSymptoms: Comments like “This is just common sense” or “We need to focus on the science” Responses:\n\nLead with data and evidence\nConnect to concrete research outcomes\nShare failure stories from high-profile collaborations\nAcknowledge their expertise while highlighting collaboration complexity\n\n\n\n\nSymptoms: Activities running long, content blocks getting rushed Solutions:\n\nUse visible timers for all activities\nGive time warnings (5 minutes, 2 minutes, wrap up)\nHave abbreviated versions of activities ready\nCut content, not activities - the practice is more valuable\n\n\n\n\nSymptoms: Same people speaking repeatedly, others withdrawing Interventions:\n\nUse structured turn-taking (“Each person shares one idea”)\nRedirect: “Thank you, John. Sarah, what’s your perspective?”\nAddress privately during breaks if necessary\nUse written activities to balance participation\n\n\n\n\nSymptoms: “That research doesn’t apply to our field/situation” Responses:\n\nAsk for specific context that makes it different\nFind research from their discipline if possible\nFocus on principles rather than specific practices\nInvite them to test and report back\n\n\n\n\nSymptoms: Platform crashes, connectivity issues, lost materials Preparation:\n\nHave low-tech backup plans for all activities\nTest technology multiple times before session\nPrepare printed materials as backup\nDesignate a tech support person if possible\n\n\n\n\n\n\n\n\n\nFlipchart paper and markers\nSticky notes (multiple colors)\nTimer (visible to all participants)\nName tags\nHandout packets for each participant\nLaptop and projection capability\n\n\n\n\n\nSlide deck loaded and tested\nActivity templates in shared folder\nCollaboration platform set up and tested\nContact information collection method\nEvaluation survey ready to deploy\n\n\n\n\n\nAll activities have non-digital versions\nKey content available in handout form\nAlternative room arrangements considered\nContact information for technical support"
  },
  {
    "objectID": "facilitator-guide.html#pre-session-preparation",
    "href": "facilitator-guide.html#pre-session-preparation",
    "title": "Facilitator Guide",
    "section": "",
    "text": "In-Person:\n\nTables for 4-6 people (collaborative seating)\nWall space for posting flipchart sheets\nSupplies: markers, sticky notes, timer, flipchart paper\nName tags with first names only\n\nVirtual:\n\nPre-configured breakout rooms (4-5 people each)\nShared collaboration tool (Miro, Jamboard, or Padlet)\nPolls/surveys ready in platform\nChat moderation plan\n\n\n\n\n\nYou’re a guide, not a guru: Your science expertise gives you credibility, but participants’ experiences drive learning\nEmbrace productive discomfort: Some activities may feel unfamiliar - that’s intentional\nModel vulnerability: Share your own collaboration challenges when appropriate"
  },
  {
    "objectID": "facilitator-guide.html#module-1-foundations-of-team-science-30-minutes",
    "href": "facilitator-guide.html#module-1-foundations-of-team-science-30-minutes",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Say: “Raise your hand if you’ve ever been part of a research collaboration that felt effortless and productive.” [Pause for hands] “Keep your hand up if you’ve been part of one that was frustrating or unproductive.” [Usually more hands go up]\nTransition: “Today we’re going to unpack why some collaborations soar while others struggle, using evidence from the science of team science itself.”\n\n\n\nData to Share:\n\n2007 study of 19.9 million papers showed teams produce higher-impact research\nNobel Prize data: 42% of physics prizes since 2000 went to collaborations\nNIH success rates higher for multi-PI grants in many programs\n\nDiscussion Prompt: “What drives this trend toward collaboration in your field?”\nListen for: Complexity of problems, resource needs, interdisciplinary requirements, technology demands\nBridge: “But collaboration isn’t automatically better - it has to be done well.”\n\n\n\nCommon Failure Modes (present as bullets on slide):\n\nCoordination loss: Too much time spent organizing, not enough creating\nSocial loafing: Some members contribute less in group settings\nGroupthink: Pressure for consensus stifles critical thinking\nProcess conflict: Disagreements about how to work together\nGoal misalignment: Different objectives or success metrics\n\nFacilitator Note: Don’t dwell on failures - this sets up the solution-focused content ahead.\n\n\n\nThe IMPACT Framework:\n\nInterdependence: Members need each other to succeed\nMotivation: Shared purpose and individual engagement\nProcesses: Clear workflows and communication protocols\nAbilities: Complementary skills and expertise\nCulture: Trust, psychological safety, inclusion norms\nTools: Infrastructure for collaboration and data sharing\n\nFacilitator Tip: This framework threads through the entire training - refer back to it throughout.\n\n\n\n\n\n\nInstructions to Give: “Think of a research collaboration you’ve been part of - current or recent. Rate it on these six dimensions using a 1-5 scale, where 1 is ‘major weakness’ and 5 is ‘major strength.’ Be honest - this is for your learning.”\nDimensions to Rate:\n\nClear shared goals: Everyone understood what we were trying to achieve\nComplementary expertise: Team had the right mix of skills and knowledge\nEffective communication: Information flowed well, meetings were productive\nEquitable participation: All voices were heard, contributions were valued\nConflict resolution: We handled disagreements constructively\nResource sharing: Data, materials, and tools were accessible to team members\n\nFacilitator Actions:\n\nWalk around, but don’t look over shoulders\nGive 1-minute and 30-second warnings\nModel reflection by jotting your own notes\n\n\n\n\nInstructions: “Form groups of 4-5. Each person shares: 1. One area where your team was strongest (highest score) 2. One area that was most challenging (lowest score) 3. Don’t name the team or people - focus on the dynamics”\nYour Role:\n\nVisit each group briefly, listen for patterns\nNote common strengths and challenges on your notepad\nPrepare to synthesize themes in debrief\n\nListen for These Patterns:\n\nStrengths: Often include shared excitement about the problem, clear expertise divisions, strong PI leadership\nChallenges: Frequently communication breakdowns, unclear roles, data sharing difficulties, conflict avoidance\n\n\n\n\nProcess:\n\n“What themes did you hear in your groups about team strengths?”\n“What about common challenges?”\nCapture responses on flipchart/screen\n“Great - we’re going to address many of these challenges directly in our time together”\n\nTransition: “Let’s start with one of the most commonly cited issues: communication.”"
  },
  {
    "objectID": "facilitator-guide.html#module-2-communication-architecture-45-minutes",
    "href": "facilitator-guide.html#module-2-communication-architecture-45-minutes",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Say: “In that last activity, how many groups mentioned communication as a challenge?” [Show of hands] “Communication issues aren’t just annoying - they’re expensive. MIT research shows that poor communication costs organizations an average of $62.4 million per year.”\n\n\n\nPresent Framework: “Effective team communication has four essential elements - the 4 C’s:”\nClarity | Cadence | Channels | Culture\n“Let’s unpack each one with some science behind it.”\n\n\n\nResearch Basis: Hackman’s research on team design shows that clarity of purpose and process predicts team success better than member characteristics.\nPractical Application:\n\nMeeting agendas with time allocations\nDecision logs (what was decided, by whom, when)\nAction items with owners and deadlines\nShared glossaries for technical terms across disciplines\n\nDiscussion Prompt: “What happens in your experience when roles or expectations aren’t clear?”\nListen for: Duplicated work, missed deadlines, conflict, frustration\n\n\n\nResearch Basis: Gersick’s punctuated equilibrium model shows teams need regular check-ins to maintain momentum and adjust course.\nPractical Framework:\n\nDaily/Weekly: Tactical coordination (brief, operational)\nBi-weekly/Monthly: Strategic review (longer, reflective)\nQuarterly: Relationship maintenance (team building, big picture)\nAs-needed: Crisis management (rapid response protocols)\n\nKey Point: “Consistency matters more than frequency. Better to have monthly meetings that always happen than weekly ones that get cancelled.”\n\n\n\nResearch Basis: Media richness theory - different types of information need different communication channels.\nChannel Selection Guide:\n\nFace-to-face/Video: Complex discussions, sensitive topics, brainstorming\nPhone: Quick decisions, relationship building\nEmail: Documentation, detailed information sharing, non-urgent items\nChat/Slack: Quick questions, coordination, social connection\nShared documents: Collaborative creation, version control\n\nCommon Mistake: “Using email for everything. Email is terrible for discussions but great for decisions.”\n\n\n\nResearch Basis: Google’s Project Aristotle found psychological safety was the #1 predictor of team performance.\nEdmondson’s Definition: “A shared belief that the team is safe for interpersonal risk-taking.”\nObservable Behaviors:\n\nPeople ask questions without fear of appearing ignorant\nMistakes are discussed openly as learning opportunities\nDisagreement is expressed respectfully and directly\nDifferent perspectives are actively sought\n\nKey Insight: “This doesn’t mean being ‘nice’ all the time - it means being direct and kind simultaneously.”\n\n\n\n\n\n\nForm Teams: “Count off 1-5, find your number group. You’re going to create a communication charter that a real research team could use.”\nMaterials: Provide charter template, example excerpts, channel decision tree\n\n\n\nInstructions to Teams: “Imagine you’re starting a 2-year collaborative research project. Create a communication charter addressing these areas:”\nCharter Elements: 1. Communication Values (3-4 core principles) 2. Meeting Rhythms (frequency, duration, purpose of different meeting types) 3. Channel Guidelines (what goes where, response time expectations) 4. Decision-Making Process (how choices get made, who has input vs. final say) 5. Conflict Resolution (steps for handling disagreements)\nYour Role as Facilitator:\n\nCirculate between teams\nAsk clarifying questions: “How would this work in practice?” “What if someone doesn’t follow this?”\nKeep energy up with time calls\nLook for innovative approaches to highlight\n\nCommon Sticking Points and Responses:\n\n“This is too rigid” → “Think of it as a default, not a rule. You can always deviate with agreement”\n“Our team is different” → “Absolutely - customize this to your context”\n“We don’t have time for all these meetings” → “What’s the cost of poor coordination?”\n\n\n\n\nProcess: 1. Teams pair up and exchange charters 2. Each team provides feedback using this structure: - One strength: What works well in this charter? - One question: What needs clarification? - One suggestion: How could this be improved or strengthened?\nFeedback Guidelines to Share:\n\nBe specific rather than general\nFocus on workability, not personal preferences\nAsk questions if something is unclear\n\nYour Role:\n\nMonitor feedback quality - intervene if it’s too vague or harsh\nHelp teams stay on time\nNote particularly creative solutions for later sharing\n\n\n\n\n“Take the feedback you received and make one concrete revision to your charter.”\nWhy This Matters: Teams that practice giving and receiving feedback in low-stakes situations do better when conflicts arise."
  },
  {
    "objectID": "facilitator-guide.html#module-3-governance-and-leadership-models-40-minutes",
    "href": "facilitator-guide.html#module-3-governance-and-leadership-models-40-minutes",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Say: “Communication helps teams work day-to-day, but governance determines how teams make big decisions and handle authority. Let’s look at what research tells us about structures that actually work.”\n\n\n\nKey Distinction:\n\nManagement: Day-to-day operations, task coordination, resource allocation\nGovernance: Decision rights, accountability structures, conflict resolution, strategic direction\n\nWhy It Matters: “Many teams focus only on management and wonder why they struggle with bigger decisions.”\n\n\n\nCore Principle: Different people lead different aspects based on expertise and interest.\nResearch Support: Pearce & Conger’s studies show distributed leadership increases team performance in knowledge work.\nStructure Example:\n\nScientific Leadership: Domain expert guides research direction\nOperational Leadership: Project manager handles logistics, timelines\nExternal Leadership: Senior person manages stakeholder relationships\nInnovation Leadership: Creative thinker drives new approaches\n\nPros: Leverages expertise, develops multiple people, reduces single points of failure Cons: Can be confusing if roles aren’t clear, may slow some decisions\nWhen It Works Best: Diverse, highly skilled teams with complex projects\n\n\n\nCore Principle: Leadership rotates based on project phase or expertise needs.\nReal Example: “In the Human Genome Project, different institutions led different phases based on their comparative advantages.”\nStructure Example:\n\nPhase 1: Data collection led by field research expert\nPhase 2: Analysis led by computational specialist\nPhase 3: Dissemination led by policy expert\n\nPros: Matches expertise to needs, develops multiple leaders Cons: Requires smooth handoffs, can create discontinuity\n\n\n\nCore Principle: Clear hierarchy with democratic input mechanisms.\nResearch Support: Tannenbaum & Schmidt’s leadership continuum research shows this balances efficiency with engagement.\nStructure Example:\n\nPrincipal Investigator: Final decision authority, external accountability\nAdvisory Council: Representative input from all stakeholder groups\nWorking Groups: Delegated authority for specific domains\n\nDecision Process:\n\nWorking groups develop recommendations\nAdvisory council provides input and alternatives\nPI makes final decision with transparent rationale\n\nPros: Clear accountability, incorporates diverse input, efficient Cons: Can feel top-down if not implemented well\n\n\n\nCore Principle: Hub-and-spoke coordination across autonomous units.\nReal Example: “Think of how the Large Hadron Collider collaboration works - thousands of scientists across hundreds of institutions.”\nStructure:\n\nCentral Coordination Hub: Manages overall project, standards, resources\nAutonomous Nodes: Independent teams with specific responsibilities\nLiaison Roles: Boundary spanners who connect nodes\n\nPros: Scales to large collaborations, maintains autonomy Cons: Complex coordination, potential for fragmentation\nKey Success Factor: Strong coordination mechanisms and shared standards\n\n\n\n\n\n\nFour Scenarios - Assign One Per Team:\n\nMulti-institutional Clinical Trial\n\n5 medical centers, 200 patients, 3-year timeline\nRegulatory compliance requirements, patient safety critical\n$2M budget, industry sponsor\n\nInterdisciplinary Data Analysis Consortium\n\nComputer scientists, social scientists, domain experts\nLarge shared dataset, multiple research questions\nDifferent publication norms across disciplines\n\nInternational Field Research Collaboration\n\nTeams from 4 countries, remote field sites\nEquipment sharing, varying resource levels\nDifferent institutional policies and cultures\n\nIndustry-Academic Partnership\n\nUniversity researchers + company R&D team\nProprietary data concerns, different timelines\nAcademic freedom vs. commercial interests\n\n\n\n\n\nInstructions to Teams: “Design a governance structure for your scenario. Address these key elements:”\nGovernance Elements to Address:\n\nLeadership Structure: Who has authority for what decisions?\nDecision-Making Process: How are key choices made?\nConflict Resolution: What happens when people disagree?\nResource Allocation: How are shared resources managed?\nCredit and Recognition: How are contributions acknowledged?\n\nDeliverable: Create a visual representation (flowchart, org chart, process diagram) that shows your governance model.\nYour Facilitation Approach:\n\nVisit each team twice during the 15 minutes\nFirst visit (5-7 min): Check understanding, clarify scenario details\nSecond visit (10-12 min): Push thinking with questions:\n\n“What happens if this person leaves the project?”\n“How do you handle a major disagreement using this structure?”\n“Where might this break down under pressure?”\n\n\nCommon Challenges and Responses:\n\nTeams default to simple hierarchy → “What are the downsides of that approach for this scenario?”\nTeams create overly complex structures → “How would new team members understand this?”\nTeams ignore the human dynamics → “What about trust, communication, relationships?”\n\n\n\n\nProcess:\n\nTeams post their governance designs around the room\nEveryone walks around and reviews all designs\nEach person gets 2 dot stickers to vote for:\n\nMost innovative approach\nMost practical for real implementation\n\n\nDebrief Questions:\n\n“What patterns do you see across the designs?”\n“What creative solutions surprised you?”\n“What would make these governance models actually work in practice?”"
  },
  {
    "objectID": "facilitator-guide.html#module-4-data-sharing-and-resource-management-35-minutes",
    "href": "facilitator-guide.html#module-4-data-sharing-and-resource-management-35-minutes",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Ask: “How many of you have been part of a collaboration where data sharing was seamless and easy?” [Few hands usually go up]\nSay: “Data sharing is often the biggest practical barrier to effective collaboration. Let’s look at frameworks that make it work.”\n\n\n\nPresent Framework: “The FAIR principles were designed for open science, but we need to extend them for collaborative team science.”\nFAIR Principles:\n\nFindable: Team members can locate relevant data and resources\nAccessible: Appropriate permissions and access protocols exist\nInteroperable: Data works across different systems and analyses\nReusable: Clear documentation enables future use\n\nThe ‘+’ Addition:\n\nSecure: Privacy, confidentiality, and compliance protections\n\n\n\n\nCommon Problem: “The data exists somewhere, but no one can find it when they need it.”\nSolutions:\n\nCentral registry of all project datasets with descriptions\nConsistent naming conventions for files and versions\nMetadata templates that everyone uses\nSearch functionality within shared repositories\n\nQuick Example: “Instead of ‘Analysis_final_v3_JMS.xlsx’, use ‘2024-03-15_participant-survey_cleaned_smith.xlsx’”\n\n\n\nKey Principle: “Default to open within the team, closed to the outside, with explicit exceptions.”\nAccess Levels:\n\nFull Access: Core team members, can read/write/modify\nAnalysis Access: Can download and analyze, cannot modify originals\n\nMetadata Access: Can see what exists, request specific datasets\nNo Access: Sensitive data with special restrictions\n\nImplementation Tools:\n\nCloud platforms with granular permissions (Google Drive, Box, institutional systems)\nVersion control systems (Git for code, specialized tools for data)\nAccess logging for sensitive data compliance\n\n\n\n\nCommon Failure: “Everyone saves data in their preferred format, nothing works together.”\nBest Practices:\n\nAgreed-upon file formats for different data types\nStandard variable naming across datasets\nCommon coding schemes for categorical variables\nDocumentation templates that everyone uses\n\n\n\n\nThe Documentation Imperative: “If you can’t understand the data 6 months from now, no one else will either.”\nEssential Documentation:\n\nData collection protocols and any changes over time\nVariable definitions and coding schemes\nQuality control procedures and known limitations\nAnalysis scripts with comments explaining logic\n\n\n\n\n\n\n\nScenario: Multi-site study examining social media use and mental health outcomes among adolescents. Site A (major university) has collected data from 500 participants. Site B (smaller college) wants to access this data for secondary analysis.\nRoles (5 people per group):\n\nSite A Principal Investigator: Collected the data, protective of participants\nSite B Researcher: Wants access for legitimate secondary research\nSite A Compliance Officer: Responsible for legal/ethical compliance\nSite B IRB Representative: Must ensure ethical standards\nData Manager: Technical expert on security and systems\n\nKey Constraints:\n\nData includes sensitive mental health information\nParticipants consented to “research by the study team and approved collaborators”\nSite A IRB approval required for data sharing\nSite B has different data security infrastructure\n\n\n\n\nInstructions to Groups: “You have 15 minutes to negotiate a data sharing agreement. You must address these issues:”\nRequired Agreement Elements:\n\nWhat data can be shared? (raw data, processed data, aggregate data only?)\nAccess controls: How will Site B access and store the data?\nPermitted analyses: What research questions can Site B pursue?\nPublication rights: How are publications handled? Authorship?\nSecurity requirements: What technical safeguards are needed?\nCompliance verification: How is adherence to agreement monitored?\n\nYour Facilitation Strategy:\n\nLet tensions emerge naturally - don’t smooth over disagreements too quickly\nIntervene only if discussion becomes personal or completely stuck\nNote common sticking points for debrief discussion\nWatch for creative solutions that balance competing interests\n\nCommon Sticking Points You’ll Observe:\n\nSite A wants extensive oversight, Site B wants autonomy\nPublication timelines and approval processes\nTechnical security requirements vs. practical constraints\nWhat happens if Site B violates the agreement\n\n\n\n\nDebrief Questions:\n\n“What was hardest to negotiate? Why?”\n“What solutions did you find for balancing protection with access?”\n“How did the different perspectives (PI vs. compliance vs. IRB) create tension?”\n“What would make this process easier in real life?”\n\nKey Learning Points to Draw Out:\n\nStart data sharing conversations early in collaboration planning\nDifferent stakeholders have legitimate but competing concerns\nTechnical solutions can resolve some trust issues\nClear agreements prevent bigger conflicts later\nTemplates and institutional support make negotiations faster\n\nTransition: “Data sharing is often where issues of fairness and inclusion become most visible. Let’s talk about building teams where everyone can contribute effectively.”"
  },
  {
    "objectID": "facilitator-guide.html#module-5-building-inclusive-and-productive-teams-30-minutes",
    "href": "facilitator-guide.html#module-5-building-inclusive-and-productive-teams-30-minutes",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Research Foundation: “Three key findings from team performance research:”\n\nDiverse teams outperform homogeneous teams on complex problems (Page 2007)\nBut diversity alone isn’t enough - inclusion practices determine whether diversity helps or hurts (Nishii 2013)\nSmall changes in process can have big impacts on who participates and how (Woolley 2010)\n\nKey Insight: “Diversity is about composition. Inclusion is about behavior.”\n\n\n\nSurface-Level Diversity:\n\nDemographics: gender, race, age, nationality\nDisciplinary backgrounds\nInstitutional affiliations\nCareer stages\n\nDeep-Level Diversity:\n\nThinking styles (analytical vs. intuitive)\nWork preferences (individual vs. collaborative)\nCommunication styles (direct vs. indirect)\nRisk tolerance (conservative vs. experimental)\n\nWhy This Matters: “Surface-level diversity is what we see first, but deep-level diversity often drives the performance benefits.”\n\n\n\nAllport’s Contact Theory: Under the right conditions, contact between different groups reduces bias and improves collaboration.\nThe Right Conditions for Research Teams:\n\nEqual status within the collaboration context\nCommon goals that require interdependence\nIntergroup contact in cooperative (not competitive) settings\nAuthority support for collaborative norms\n\nPractical Application: “This means actively creating opportunities for different team members to work together as equals on shared objectives.”\n\n\n\nStrategy 1: Structured Brainstorming\n\nProblem: Extroverted team members dominate idea generation\nSolution: Silent brainstorming → individual sharing → group building\n\nStrategy 2: Devil’s Advocate Protocols\n\nProblem: Pressure for false consensus\nSolution: Assign someone to argue alternative perspectives\n\nStrategy 3: Multiple Communication Channels\n\nProblem: Some people don’t speak up in meetings\nSolution: Combine verbal discussion, written input, and one-on-one check-ins\n\nStrategy 4: Bias Interruption\n\nProblem: Unconscious biases affect evaluation of ideas and contributions\nSolution: Structured evaluation criteria, diverse review panels\n\nStrategy 5: Cultural Bridge-Building\n\nProblem: Different professional cultures have different norms\nSolution: Explicit discussion of differences, negotiated team norms\n\n\n\n\n\n\n\nInstructions: “Think about a current or recent research collaboration. Rate how well the team does on each inclusion indicator using a 1-5 scale.”\nInclusion Indicators:\n\nDiverse representation in leadership and decision-making roles\nEquitable participation in meetings and discussions\nMultiple communication styles are accommodated and valued\nDifferent perspectives are actively sought on important decisions\nCultural differences are acknowledged and leveraged as strengths\nBias mitigation strategies are used in evaluation and selection processes\nConflict resolution addresses both task and relationship issues\nRecognition and credit are distributed fairly across contributions\n\nFacilitator Notes:\n\nWalk around but maintain privacy\nNotice if people seem stuck - offer to clarify any indicators\nThis should be reflective, not judgmental\n\n\n\n\nPartner Assignment: “Find someone you don’t know well or haven’t worked with closely.”\nConversation Structure: Round 1 (3 minutes each person): Share assessment results\n\nWhich areas scored highest? What makes those work well?\nWhich areas scored lowest? What barriers do you see?\nDon’t problem-solve yet - just understand each other’s situations\n\nRound 2 (4 minutes total): Collaborative action planning\n\nChoose 2-3 priority areas for improvement\nBrainstorm specific, actionable strategies\nConsider: What would you try first? What support would you need?\n\nFacilitation Approach: - Circulate to listen for innovative ideas - Help pairs stay focused on actionable steps - Note themes for whole-group debrief\nCommon Challenges and Responses:\n\n“Our team is already pretty inclusive” → “That’s great! What could you share with other teams?”\n“These problems are too big for me to solve” → “What’s one small experiment you could try?”\n“I’m not in a leadership position” → “What can you influence from your current role?”"
  },
  {
    "objectID": "facilitator-guide.html#module-6-implementation-and-sustainability-20-minutes",
    "href": "facilitator-guide.html#module-6-implementation-and-sustainability-20-minutes",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Reality Check: “Research on training effectiveness shows that without deliberate implementation support, people use about 10% of what they learn in programs like this.”\nWhy Implementation Fails: - Return to urgent daily pressures - Lack of organizational support - Trying to change too much at once - No accountability mechanisms\n\n\n\nPilot Approach: “Pick one practice, try it with one team, for one month.”\nExamples of Good Starting Points:\n\nCommunication: Implement structured agendas for one regular meeting\nGovernance: Create decision logs for one ongoing project\nData sharing: Establish naming conventions for one shared folder\nInclusion: Try silent brainstorming in one team meeting\n\nWhy This Works: Small wins build confidence and demonstrate value before scaling up.\n\n\n\nSimple Metrics for Team Effectiveness:\n\nEfficiency: Meeting satisfaction scores, time to decision\nInnovation: Number of new ideas generated, creative solutions adopted\nRelationships: Trust levels, conflict resolution speed\nOutcomes: Progress toward goals, quality of deliverables\n\nThe Learning Mindset: “Expect that your first attempts won’t be perfect. The goal is to learn and improve, not to implement flawlessly.”\n\n\n\nScaling Principles:\n\nAdapt, don’t just adopt: What works for one team may need modification for another\nBuild champions: Find early adopters who can help spread practices\nCreate systems support: Templates, training, and infrastructure\nAddress resistance: Understand and respond to legitimate concerns\n\nCommon Scaling Mistakes:\n\nMandating practices without buy-in\nIgnoring context differences\nMoving too fast without solidifying early wins\n\n\n\n\n\n\n\nInstructions: “Complete this action plan for yourself. Be specific and realistic.”\nTemplate Elements: 1. One thing I’ll stop doing in my research collaborations - Example: Stop sending unclear emails that require multiple follow-ups\n\nOne thing I’ll start doing within the next 30 days\n\nExample: Create a communication charter for my current project team\n\nOne practice I’ll advocate for in my existing teams\n\nExample: Propose using structured brainstorming for our next planning meeting\n\nMy accountability partner from this session\n\nName and contact information of someone who will check in with you\n\nCheck-in date to assess progress\n\nSpecific date within 60 days to review how implementation is going\n\nOne resource I need to make this work\n\nExample: Template for data sharing agreements, support from my department chair\n\n\nFacilitator Role:\n\nCirculate to answer questions and provide encouragement\nHelp people make their commitments specific and measurable\nConnect people who might be good accountability partners\n\n\n\n\nProcess: “Would anyone like to share one commitment with the group? This can help with accountability.”\nWhy This Works: Public commitments have higher follow-through rates.\nFacilitation Tips:\n\nDon’t pressure anyone to share\nCelebrate creative or ambitious commitments\nNote themes across commitments"
  },
  {
    "objectID": "facilitator-guide.html#post-session-follow-up",
    "href": "facilitator-guide.html#post-session-follow-up",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Send thank you email with session materials\nShare contact information for accountability partnerships\nProvide resource links and templates\n\n\n\n\n\nBrief survey on implementation attempts\nVirtual “office hours” for questions\nShare success stories and challenges\n\n\n\n\n\nFollow-up survey on sustained practice changes\nAdvanced workshop for graduates\nCommunity of practice formation"
  },
  {
    "objectID": "facilitator-guide.html#troubleshooting-common-facilitation-challenges",
    "href": "facilitator-guide.html#troubleshooting-common-facilitation-challenges",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Symptoms: Quiet groups, minimal discussion, brief activity outputs Interventions:\n\nUse smaller groups (3-4 people)\nProvide more structure and specific prompts\nModel vulnerability by sharing your own experiences\nUse anonymous input methods (sticky notes, digital polls)\n\n\n\n\nSymptoms: Comments like “This is just common sense” or “We need to focus on the science” Responses:\n\nLead with data and evidence\nConnect to concrete research outcomes\nShare failure stories from high-profile collaborations\nAcknowledge their expertise while highlighting collaboration complexity\n\n\n\n\nSymptoms: Activities running long, content blocks getting rushed Solutions:\n\nUse visible timers for all activities\nGive time warnings (5 minutes, 2 minutes, wrap up)\nHave abbreviated versions of activities ready\nCut content, not activities - the practice is more valuable\n\n\n\n\nSymptoms: Same people speaking repeatedly, others withdrawing Interventions:\n\nUse structured turn-taking (“Each person shares one idea”)\nRedirect: “Thank you, John. Sarah, what’s your perspective?”\nAddress privately during breaks if necessary\nUse written activities to balance participation\n\n\n\n\nSymptoms: “That research doesn’t apply to our field/situation” Responses:\n\nAsk for specific context that makes it different\nFind research from their discipline if possible\nFocus on principles rather than specific practices\nInvite them to test and report back\n\n\n\n\nSymptoms: Platform crashes, connectivity issues, lost materials Preparation:\n\nHave low-tech backup plans for all activities\nTest technology multiple times before session\nPrepare printed materials as backup\nDesignate a tech support person if possible"
  },
  {
    "objectID": "facilitator-guide.html#materials-checklist",
    "href": "facilitator-guide.html#materials-checklist",
    "title": "Facilitator Guide",
    "section": "",
    "text": "Flipchart paper and markers\nSticky notes (multiple colors)\nTimer (visible to all participants)\nName tags\nHandout packets for each participant\nLaptop and projection capability\n\n\n\n\n\nSlide deck loaded and tested\nActivity templates in shared folder\nCollaboration platform set up and tested\nContact information collection method\nEvaluation survey ready to deploy\n\n\n\n\n\nAll activities have non-digital versions\nKey content available in handout form\nAlternative room arrangements considered\nContact information for technical support"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Team Science Training Workshop",
    "section": "",
    "text": "Welcome to the Team Science Training Workshop! This comprehensive program is designed to help research teams collaborate more effectively through evidence-based practices and structured frameworks."
  },
  {
    "objectID": "index.html#workshop-overview",
    "href": "index.html#workshop-overview",
    "title": "Team Science Training Workshop",
    "section": "",
    "text": "Welcome to the Team Science Training Workshop! This comprehensive program is designed to help research teams collaborate more effectively through evidence-based practices and structured frameworks."
  },
  {
    "objectID": "index.html#workshop-goals",
    "href": "index.html#workshop-goals",
    "title": "Team Science Training Workshop",
    "section": "Workshop Goals",
    "text": "Workshop Goals\nThis training workshop aims to equip participants with the knowledge, skills, and tools needed to:\n\n1. Understand Team Science Fundamentals\n\nLearn what makes research teams effective based on scientific evidence\nIdentify common failure modes in collaborative research\nApply the IMPACT framework (Interdependence, Motivation, Processes, Abilities, Culture, Tools) to team dynamics\n\n\n\n2. Build Communication Architecture\n\nImplement the 4C Framework (Clarity, Cadence, Channels, Culture) for effective team communication\nCreate communication charters that work for real research teams\nEstablish psychological safety and inclusion norms\n\n\n\n3. Design Governance Structures\n\nUnderstand different leadership models (distributed, rotating, collaborative hierarchy, network governance)\nDesign governance structures appropriate for specific collaboration contexts\nCreate clear decision-making processes and accountability structures\n\n\n\n4. Manage Data and Resources Collaboratively\n\nApply FAIR+ principles (Findable, Accessible, Interoperable, Reusable, Secure) to team data practices\nNegotiate data sharing agreements that balance protection with access\nEstablish protocols for resource allocation and management\n\n\n\n5. Build Inclusive and Productive Teams\n\nRecognize the value of diversity in research teams\nImplement inclusion strategies that enable all team members to contribute effectively\nAddress bias and create equitable participation structures\n\n\n\n6. Implement Sustainable Practices\n\nDevelop personal action plans for improving team collaboration\nStart with small, measurable changes that demonstrate value\nBuild accountability and support systems for sustained improvement"
  },
  {
    "objectID": "index.html#training-format",
    "href": "index.html#training-format",
    "title": "Team Science Training Workshop",
    "section": "Training Format",
    "text": "Training Format\nThe workshop consists of six interactive modules combining:\n\nEvidence-based content: Research findings on team effectiveness\nHands-on activities: Practical exercises and simulations\nGroup discussions: Peer learning and knowledge sharing\nAction planning: Concrete steps for implementation"
  },
  {
    "objectID": "index.html#target-audience",
    "href": "index.html#target-audience",
    "title": "Team Science Training Workshop",
    "section": "Target Audience",
    "text": "Target Audience\nThis training is designed for:\n\nResearch team members at all career stages\nPrincipal investigators leading collaborative projects\nProject managers and coordinators\nAnyone involved in multi-institutional or interdisciplinary research"
  },
  {
    "objectID": "index.html#expected-outcomes",
    "href": "index.html#expected-outcomes",
    "title": "Team Science Training Workshop",
    "section": "Expected Outcomes",
    "text": "Expected Outcomes\nBy the end of this workshop, participants will:\n\nHave a clear understanding of what makes research teams succeed or struggle\nPossess practical frameworks and tools for improving team collaboration\nHave developed personal action plans for implementing specific practices\nBe connected with peers for ongoing learning and support"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Team Science Training Workshop",
    "section": "Getting Started",
    "text": "Getting Started\nTo begin, navigate to the Facilitator Guide for detailed instructions on delivering this training program."
  }
]